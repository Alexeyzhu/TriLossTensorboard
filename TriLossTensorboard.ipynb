{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "TriLossTensorboard.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexeyzhu/TriLossTensorboard/blob/master/TriLossTensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9FLb918-uKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H7FSJXE-uKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %reload_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YJxMfVM-uK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# logs_base_dir = \"/home/vladbakhteev/projects/alex/runs\"\n",
        "# os.makedirs(logs_base_dir, exist_ok=True)\n",
        "# %tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkGFjnGg-uLA",
        "colab_type": "code",
        "outputId": "62208183-ffdd-420d-e2ba-cb8d5a3a2f51",
        "colab": {}
      },
      "source": [
        "# from tensorboard import notebook\n",
        "# notebook.list()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Known TensorBoard instances:\n",
            "  - port 6006: logdir runs (started 2 days, 19:38:32 ago; pid 15927)\n",
            "  - port 6006: logdir runs (started 2 days, 20:39:26 ago; pid 5480)\n",
            "  - port 6008: logdir /home/mmavlyutov/alex/runs (started 1 day, 5:25:19 ago; pid 3649)\n",
            "  - port 6006: logdir runs (started 2 days, 20:02:36 ago; pid 10667)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "u-P6fZJH-uLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import io\n",
        "\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.backends import cudnn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.transforms import ToTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evTieL89-uLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loader(config):\n",
        "    svhn_transform = transforms.Compose([\n",
        "        transforms.Resize(config['image_size']),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    mnist_transform = transforms.Compose([\n",
        "        transforms.Resize(config['image_size']),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    svhn = datasets.SVHN(root=config['svhn_path'], download=True, transform=svhn_transform)\n",
        "    svhn_val = datasets.SVHN(root=config['svhn_path'], download=True, split='test', transform=svhn_transform)\n",
        "\n",
        "    mnist = datasets.MNIST(root=config['mnist_path'], download=True, transform=mnist_transform)\n",
        "    mnist_val = datasets.MNIST(root=config['mnist_path'], train=False, download=True, transform=mnist_transform)\n",
        "\n",
        "    svhn_loader = torch.utils.data.DataLoader(dataset=svhn,\n",
        "                                              batch_size=config['batch_size'],\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=config['num_workers'])\n",
        "\n",
        "    svhn_val_loader = torch.utils.data.DataLoader(dataset=svhn_val,\n",
        "                                                  batch_size=500,\n",
        "                                                  shuffle=False,\n",
        "                                                  num_workers=config['num_workers'])\n",
        "\n",
        "    mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                               batch_size=config['batch_size'],\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=config['num_workers'])\n",
        "\n",
        "    mnist_val_loader = torch.utils.data.DataLoader(dataset=mnist_val,\n",
        "                                                   batch_size=500,\n",
        "                                                   shuffle=False,\n",
        "                                                   num_workers=config['num_workers'])\n",
        "\n",
        "    return svhn_loader, svhn_val_loader, mnist_loader, mnist_val_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVCt3Jkh-uLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, latent_dim=512):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        conv_dim = 64\n",
        "        self.conv1 = conv(3, conv_dim, 5, 2, 2)\n",
        "        self.conv2 = conv(conv_dim, conv_dim * 2, 5, 2, 2)\n",
        "        self.conv3 = conv(conv_dim * 2, conv_dim * 4, 5, 2, 2)\n",
        "        self.conv4 = conv(conv_dim * 4, conv_dim * 8, 4, 1, 0)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 50)\n",
        "        self.fc4 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = F.leaky_relu(self.conv1(x), 0.05)\n",
        "        x = F.leaky_relu(self.conv2(x), 0.05)\n",
        "\n",
        "        x = F.leaky_relu(self.conv3(x), 0.05)\n",
        "        x = F.leaky_relu(self.conv4(x), 0.05)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        # Classifier\n",
        "        x_c = F.relu(self.fc1(x))\n",
        "        x_c = F.dropout(x_c, training=self.training)\n",
        "        x_c = self.fc2(x_c)\n",
        "        x_c = F.dropout(x_c, training=self.training)\n",
        "        x_c = self.fc3(x_c)\n",
        "        x_c = F.dropout(x_c, training=self.training)\n",
        "        x_c = self.fc4(x_c)\n",
        "\n",
        "        return x, F.softmax(x_c, dim=1)\n",
        "\n",
        "\n",
        "class Net_D(nn.Module):\n",
        "    def __init__(self, latent_dim=512):\n",
        "        super(Net_D, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 50)\n",
        "        self.fc4 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Discriminator\n",
        "        x_d = F.relu(self.fc1(x))\n",
        "        x_d = F.dropout(x_d, training=self.training)\n",
        "        x_d = self.fc2(x_d)\n",
        "        x_d = F.dropout(x_d, training=self.training)\n",
        "        x_d = self.fc3(x_d)\n",
        "        x_d = F.dropout(x_d, training=self.training)\n",
        "        x_d = self.fc4(x_d)\n",
        "\n",
        "        return torch.sigmoid(x_d)\n",
        "\n",
        "\n",
        "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=True))  # bias=False\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkwoFVVU-uLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(true_labels, predicted_labels):\n",
        "    _, pred = torch.max(predicted_labels, 1)\n",
        "\n",
        "    correct = np.squeeze(pred.eq(true_labels.data.view_as(pred)))\n",
        "    return correct.float().mean()\n",
        "\n",
        "\n",
        "def xavier_weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
        "        nn.init.constant_(m.bias, 0.1)\n",
        "\n",
        "\n",
        "def pseudo_labeling(target, c, m=1):\n",
        "    indexes = c[range(len(c)), torch.argmax(c, dim=1)] >= m\n",
        "    indexes = np.array(np.nonzero(indexes.cpu().numpy())).flatten()\n",
        "    pseudo_labels = c[indexes].clone()\n",
        "    pseudo_labels = (pseudo_labels == pseudo_labels.max(dim=1, keepdim=True)[0]).long()\n",
        "    _, pseudo_labels = torch.max(pseudo_labels, 1)\n",
        "    uni = np.array(np.unique(pseudo_labels.cpu().numpy(), return_counts=True))\n",
        "    mi = np.min(uni[1])\n",
        "    if len(uni[1]) < 10:\n",
        "        mi = 0\n",
        "    ma = np.max(uni[1])\n",
        "    return target[indexes], pseudo_labels, indexes, (mi + 1) / (ma + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfNXVRkn-uLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Solver(object):\n",
        "    def __init__(self, config, source_loader, source_val_loader, target_loader, target_val_loader):\n",
        "        self.source_loader = source_loader\n",
        "        self.source_val_loader = source_val_loader\n",
        "        self.target_loader = target_loader\n",
        "        self.target_val_loader = target_val_loader\n",
        "        self.net = None\n",
        "        self.net_optimizer = None\n",
        "        self.net_d = None\n",
        "        self.net_optimizer_d = None\n",
        "        self.beta1 = config['beta1']\n",
        "        self.beta2 = config['beta2']\n",
        "        self.train_iters = config['train_iters']\n",
        "        self.pretrain_iters = config['pretrain_iters']\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.lr = config['lr']\n",
        "        self.lr_d = config['lr_d']\n",
        "        self.alpha_s = config['alpha_s']\n",
        "        self.alpha_t = config['alpha_t']\n",
        "        self.beta_c = config['beta_c']\n",
        "        self.beta_sep = config['beta_sep']\n",
        "        self.beta_p = config['beta_p']\n",
        "        self.log_step = config['log_step']\n",
        "        self.model_path = config['model_path']\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.log_file = config['log_file']\n",
        "        self.plot_path = config['plot_path']\n",
        "        self.writer = SummaryWriter()\n",
        "        self.build_model()\n",
        "\n",
        "    def log(self, text):\n",
        "        print(text)\n",
        "        if self.log_file is not None:\n",
        "            with open(self.log_file, 'a') as f:\n",
        "                f.write(text + '\\n')\n",
        "                f.flush()\n",
        "                f.close()\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Builds a generator and a discriminator.\"\"\"\n",
        "        self.net = Net()\n",
        "        self.net_d = Net_D()\n",
        "\n",
        "        net_params = list(self.net.parameters())\n",
        "        net_d_params = list(self.net_d.parameters())\n",
        "        self.net_optimizer = optim.Adamax(net_params, self.lr)\n",
        "        self.net_optimizer_d = optim.Adamax(net_d_params, self.lr_d)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.net.cuda()\n",
        "            self.net_d.cuda()\n",
        "\n",
        "    def to_var(self, x):\n",
        "        \"\"\"Converts numpy to variable.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cuda()\n",
        "        return Variable(x, requires_grad=False)\n",
        "\n",
        "    def to_data(self, x):\n",
        "        \"\"\"Converts variable to numpy.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cpu()\n",
        "        return x.data.numpy()\n",
        "\n",
        "    def reset_grad(self):\n",
        "        \"\"\"Zeros the gradient buffers.\"\"\"\n",
        "        self.net_optimizer.zero_grad()\n",
        "        self.net_optimizer_d.zero_grad()\n",
        "\n",
        "    def separability_loss(self, labels, latents, imbalance_parameter=1):\n",
        "        criteria = torch.nn.modules.loss.CosineEmbeddingLoss()\n",
        "        loss_up = 0\n",
        "        one_cuda = torch.ones(1).cuda()\n",
        "        mean = torch.mean(latents, dim=0).cuda().view(1, -1)\n",
        "        loss_down = 0\n",
        "        for i in range(self.num_classes):\n",
        "            indexes = labels.eq(i)\n",
        "            mean_i = torch.mean(latents[indexes], dim=0).view(1, -1)\n",
        "            if str(mean_i.norm().item()) != 'nan':\n",
        "                for latent in latents[indexes]:\n",
        "                    loss_up += criteria(latent.view(1, -1), mean_i, one_cuda)\n",
        "                loss_down += criteria(mean, mean_i, one_cuda)\n",
        "        loss = (loss_up / loss_down) * imbalance_parameter\n",
        "        return loss\n",
        "\n",
        "    def initialisation(self):\n",
        "        self.net.apply(xavier_weights_init)\n",
        "        self.net_d.apply(xavier_weights_init)\n",
        "        source_iter = iter(self.source_loader)\n",
        "        target_iter = iter(self.target_loader)\n",
        "        target_val_iter = iter(self.target_val_loader)\n",
        "        source_per_epoch = len(source_iter)\n",
        "        target_per_epoch = len(target_iter)\n",
        "        targetval_per_epoch = len(target_val_iter)\n",
        "        self.log(f'{source_per_epoch}, {target_per_epoch}, {targetval_per_epoch}')\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        f_labels = torch.LongTensor(128)\n",
        "        f_labels[...] = 10\n",
        "\n",
        "        t_labels = torch.LongTensor(128)\n",
        "        t_labels[...] = 1\n",
        "\n",
        "        # pretrain\n",
        "        log_pre = 50\n",
        "        source_iter = iter(self.source_loader)\n",
        "        target_iter = iter(self.target_loader)\n",
        "        return criterion, source_per_epoch, target_per_epoch, target_iter, source_iter, log_pre\n",
        "    \n",
        "        \n",
        "    def train(self):\n",
        "        \n",
        "        # ============ Print latent ============#\n",
        "        # print_latent(self.net, self.target_val_loader, self.source_val_loader,'before training', self.plot_path)\n",
        "        \n",
        "        criterion, source_per_epoch, target_per_epoch, target_iter, source_iter, log_pre = self.initialisation()\n",
        "\n",
        "        pre_train = not os.path.exists(os.path.join(self.model_path, 'pre_train.pth'))\n",
        "\n",
        "        # ============ Pretrain ============#\n",
        "        if pre_train:\n",
        "            self.log(\"Pretrain:\\n*********\")\n",
        "            time_for_iter = []\n",
        "            for step in range(self.pretrain_iters + 1):\n",
        "                start_time = time.time()\n",
        "                # ============ Initialization ============#\n",
        "                # refresh\n",
        "                if (step + 1) % (source_per_epoch) == 0:\n",
        "                    source_iter = iter(self.source_loader)\n",
        "                if (step + 1) % (target_per_epoch) == 0:\n",
        "                    target_iter = iter(self.target_loader)\n",
        "                # load the data\n",
        "                source, s_labels = source_iter.next()\n",
        "                \n",
        "                target, _ = target_iter.next()\n",
        "                \n",
        "                target_rgb = target\n",
        "                target = self.to_var(target_rgb)\n",
        "                source, s_labels = self.to_var(source), self.to_var(s_labels).long().squeeze()\n",
        "\n",
        "                # ============ Training ============ #\n",
        "                self.reset_grad()\n",
        "                # forward\n",
        "                latent, c = self.net(source)\n",
        "                # loss\n",
        "                loss_source_class = criterion(c, s_labels)\n",
        "\n",
        "                # one step\n",
        "                loss_source_class.backward()\n",
        "                self.net_optimizer.step()\n",
        "                self.reset_grad()\n",
        "                # ============ Validation ============ #\n",
        "                if (step + 1) % log_pre == 0:\n",
        "                    _, c_source = self.net(source)\n",
        "                    _, c_target = self.net(target)\n",
        "                    self.log(\"[%d/%d] classification loss: %.4f; source accuracy  %.4f\" % (\n",
        "                        step + 1,self.pretrain_iters,  loss_source_class.item(), accuracy(s_labels, c_source)))\n",
        "                    \n",
        "                    self.writer.add_scalar('Classification loss/Pretrain Loss', loss_source_class.item(), step)\n",
        "                    self.writer.add_scalar('Pretrain Accuracy/source-train', accuracy(s_labels, c_source), step)\n",
        "                    tar_acc, sour_acc = self.validate()\n",
        "                    self.writer.add_scalar('Pretrain Accuracy/target-test', tar_acc, step)\n",
        "                    self.writer.add_scalar('Pretrain Accuracy/source-test', sour_acc, step)\n",
        "                    \n",
        "                    self.log('Pretrain time remaining %.1f min' %(\n",
        "                        (sum(time_for_iter) / len(time_for_iter)) * (self.pretrain_iters - step) / 60))\n",
        "                    self.writer.flush()\n",
        "                    \n",
        "                time_for_iter.append(time.time() - start_time)\n",
        "            # ============ Print latent ============#\n",
        "            self.save_model()\n",
        "        else:\n",
        "            self.load_model()\n",
        "        \n",
        "        #print_latent(self.net, self.target_val_loader, self.source_val_loader, 'after pretraining', self.plot_path)\n",
        "\n",
        "        # ============ Initialization ============ #\n",
        "        source_iter = iter(self.source_loader)\n",
        "        target_iter = iter(self.target_loader)\n",
        "        maxacc = 0.0\n",
        "        maximum_acc = 0.0\n",
        "        max_iter = 0\n",
        "        net_params = list(self.net.parameters())\n",
        "        net_d_params = list(self.net_d.parameters())\n",
        "\n",
        "        self.net_optimizer = optim.Adam(net_params, self.lr, [self.beta1, self.beta2])\n",
        "        self.net_optimizer_d = optim.Adam(net_d_params, self.lr_d, [self.beta1, self.beta2])\n",
        "        \n",
        "        self.log(\"Second:\\n******\")\n",
        "        \n",
        "        time_for_iter = []\n",
        "        for step in range(self.train_iters):\n",
        "            start_time = time.time()\n",
        "            # ============ Initialization ============#\n",
        "\n",
        "            # refresh\n",
        "            if (step + 1) % (target_per_epoch) == 0:\n",
        "                target_iter = iter(self.target_loader)\n",
        "            if (step + 1) % (source_per_epoch) == 0:\n",
        "                source_iter = iter(self.source_loader)\n",
        "            # load the data\n",
        "            source, s_labels = source_iter.next()\n",
        "            source, s_labels = self.to_var(source), self.to_var(s_labels).long().squeeze()  # must squeeze\n",
        "            target, _ = target_iter.next()\n",
        "            target_rgb = target\n",
        "            target = self.to_var(target_rgb)\n",
        "\n",
        "            # ============ train D ============#\n",
        "            self.reset_grad()\n",
        "\n",
        "            latent_source, c = self.net(source)\n",
        "            \n",
        "            d = self.net_d(latent_source)\n",
        "            loss_d_s1 = F.binary_cross_entropy(d, torch.ones_like(d, dtype=torch.float32))\n",
        "            loss_d_s0 = F.binary_cross_entropy(d, torch.zeros_like(d, dtype=torch.float32))\n",
        "            loss_c_source = criterion(c, s_labels)\n",
        "\n",
        "            latent_target, c = self.net(target)\n",
        "            \n",
        "            d = self.net_d(latent_target)\n",
        "            loss_d_t0 = F.binary_cross_entropy(d, torch.zeros_like(d, dtype=torch.float32))\n",
        "\n",
        "            loss_p = loss_d_s0\n",
        "            loss_d = loss_d_s1 + loss_d_t0\n",
        "            # ============ train pseudo labeling ============#\n",
        "\n",
        "            chosen_target, pseudo_labels, indexes, imbalance_parameter = pseudo_labeling(target, c)\n",
        "\n",
        "            if chosen_target is not None:\n",
        "                loss_c_target = criterion(c[indexes], pseudo_labels)\n",
        "\n",
        "                latent_target = latent_target[indexes]\n",
        "                # ============ class loss  ============#\n",
        "                loss_sep = self.separability_loss(torch.cat((s_labels, pseudo_labels)),\n",
        "                                                  torch.cat((latent_source, latent_target)),\n",
        "                                                  imbalance_parameter=imbalance_parameter)\n",
        "            else:\n",
        "                loss_c_target = 0\n",
        "                loss_sep = 0\n",
        "            loss = self.beta_c * (self.alpha_s * loss_c_source + self.alpha_t * loss_c_target) + \\\n",
        "                   self.beta_p * loss_p + \\\n",
        "                   self.beta_sep * loss_sep\n",
        "\n",
        "            loss.backward(retain_graph=True)\n",
        "            self.net_optimizer.step()\n",
        "\n",
        "            loss_d.backward()\n",
        "            self.net_optimizer_d.step()\n",
        "\n",
        "            self.reset_grad()\n",
        "\n",
        "            # ============ Validation ============ #\n",
        "            if (step + 1) % self.log_step == 0:\n",
        "                _, c_source = self.net(source)\n",
        "                _, c_target = self.net(target)\n",
        "                \n",
        "                self.log(f'Iteration [{step+1} / {self.train_iters}]')\n",
        "                self.log(\"Max accuracy: %.2f on iteration %d; Current source  accuracy  %.4f\" \n",
        "                         % (maximum_acc, max_iter, accuracy(s_labels, c_source)))\n",
        "                \n",
        "                self.writer.add_scalar('Classification loss/Train Loss', loss.item(), step)\n",
        "                self.writer.add_scalar('Train Accuracy/source-train', accuracy(s_labels, c_source), step)\n",
        "                acc, sour_acc = self.validate()\n",
        "                self.writer.add_scalar('Train Accuracy/target-test', acc, step)\n",
        "                self.writer.add_scalar('Train Accuracy/source-test', sour_acc, step)\n",
        "                self.writer.flush()\n",
        "                \n",
        "                if acc > maximum_acc:\n",
        "                    maximum_acc = acc\n",
        "                    max_iter = step\n",
        "                    \n",
        "                self.log('Train time remaining %.1f min' %(\n",
        "                    sum(time_for_iter) / len(time_for_iter) * (self.train_iters - step) / 60))\n",
        "                \n",
        "            time_for_iter.append(time.time() - start_time)\n",
        "            \n",
        "            self.reset_grad()\n",
        "            \n",
        "        self.validate(True)\n",
        "        #============Print latent space============#\n",
        "        # print_latent(self.net, self.target_val_loader, self.source_val_loader, 'after training', self.plot_path)\n",
        "        \n",
        "        # ============ Save the model ============ #\n",
        "        torch.save(self.net, \"./model_c_final.pth\")\n",
        "        torch.save(self.net_d, \"./model_d_final.pth\")\n",
        "        self.writer.close()\n",
        "\n",
        "    def validate(self, details = False):\n",
        "        class_correct = [0] * self.num_classes\n",
        "        class_total = [0.] * self.num_classes\n",
        "        classes = [str(i) for i in range(self.num_classes)]\n",
        "        self.net.eval()  # prep model for evaluation\n",
        "\n",
        "        for data, target in self.target_val_loader:\n",
        "\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            data, target = self.to_var(data), self.to_var(target).long().squeeze()\n",
        "\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            latent, output = self.net(data)\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "            # calculate test accuracy for each object class\n",
        "            for i in range(len(target.data)):\n",
        "                label = target.data[i]\n",
        "                class_correct[label] += correct[i].item()\n",
        "                class_total[label] += 1\n",
        "        \n",
        "        if details:\n",
        "            for i in range(self.num_classes):\n",
        "                if class_total[i] > 0:\n",
        "                    self.log('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "                        str(i), 100 * class_correct[i] / class_total[i],\n",
        "                        np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "                else:\n",
        "                    self.log('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "            \n",
        "        target_accuracy = 100. * np.sum(class_correct) / np.sum(class_total)\n",
        "        \n",
        "        self.log(\"\\nTest Target Accuracy (Overall) [%d / %d]: %2d%%\" \n",
        "                 % (np.sum(class_correct), np.sum(class_total), target_accuracy))\n",
        "        \n",
        "        class_correct = [0] * self.num_classes\n",
        "        class_total = [0.] * self.num_classes\n",
        "        classes = [str(i) for i in range(self.num_classes)]\n",
        "        \n",
        "        for data, target in self.source_val_loader:\n",
        "\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            data, target = self.to_var(data), self.to_var(target).long().squeeze()\n",
        "\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            latent, output = self.net(data)\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "            # calculate test accuracy for each object class\n",
        "            for i in range(len(target.data)):\n",
        "                label = target.data[i]\n",
        "                class_correct[label] += correct[i].item()\n",
        "                class_total[label] += 1\n",
        "        \n",
        "        source_accuracy = 100. * np.sum(class_correct) / np.sum(class_total)\n",
        "        \n",
        "        self.log(\"\\nTest Source Accuracy (Overall) [%d / %d]: %2d%%\" \n",
        "                 % (np.sum(class_correct), np.sum(class_total), source_accuracy))\n",
        "        \n",
        "        self.net.train()\n",
        "        return target_accuracy, source_accuracy\n",
        "\n",
        "    def save_model(self):\n",
        "        torch.save(self.net, os.path.join(self.model_path, 'pre_train.pth'))\n",
        "\n",
        "    def load_model(self):\n",
        "        self.net = torch.load(os.path.join(self.model_path, 'pre_train.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q307NWM-uL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_latent(model, target_val_loader, source_val_loader, title, plot_path):\n",
        "        \n",
        "        target, t_labels = get_all_data(target_val_loader)\n",
        "        \n",
        "        latent, _ = model(target.cuda())\n",
        "        plot_latent_space(plot_path, latent.detach().cpu().numpy(), t_labels.numpy(), 'Target ' + title)\n",
        "        \n",
        "        source, s_labels = get_all_data(source_val_loader, MNIST = False)\n",
        "            \n",
        "        latent, _ = model(source.cuda())\n",
        "        plot_latent_space(plot_path, latent.detach().cpu().numpy(), s_labels.numpy(), 'Source ' + title)\n",
        "        \n",
        "        \n",
        "        latent, _ = model(torch.cat((target, source),0).cuda())\n",
        "        \n",
        "        plot_latent_space(\n",
        "            plot_path, latent.detach().cpu().numpy(), \n",
        "            torch.cat((t_labels, s_labels), 0).cpu().numpy(), \n",
        "            'Target and Source ' + title, \n",
        "            torch.cat((\n",
        "                torch.zeros((t_labels.size()[0], )), \n",
        "                torch.ones((s_labels.size()[0], ))), 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifkCoEL4-uL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_data(data_loader, MNIST = True):\n",
        "    labels = None\n",
        "    images = None\n",
        "    i = 0\n",
        "    \n",
        "    for data, target  in data_loader:\n",
        "        if i > 9:\n",
        "            break\n",
        "        data, target = data.cpu(), target.cpu()\n",
        "        if labels is None:\n",
        "            labels = target\n",
        "            images = data\n",
        "        else:\n",
        "            labels = torch.cat((labels, target), 0)\n",
        "            images = torch.cat((images, data), 0)\n",
        "            \n",
        "        i+=1\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg5wZhtW-uMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_latent_space(plot_path, X, y, title, dataset = None):\n",
        "    \n",
        "    print(f'Images shape: {X.shape}')\n",
        "    print(f'Labels shape: {y.shape}')\n",
        "\n",
        "    feat_cols = [ 'pixel' + str(i) for i in range(X.shape[1]) ]\n",
        "    df = pd.DataFrame(X,columns=feat_cols)\n",
        "    df['y'] = y\n",
        "    \n",
        "    if dataset is not None:\n",
        "        dataset = dataset.cpu().numpy()\n",
        "        df['class'] = dataset\n",
        "        \n",
        "    df['label'] = df['y'].apply(lambda i: str(i))\n",
        "    X, y = None, None\n",
        "    \n",
        "    print('Size of the dataframe: {}'.format(df.shape))\n",
        "\n",
        "    rndperm = np.random.permutation(df.shape[0])\n",
        "    \n",
        "    N = 10000\n",
        "\n",
        "    df_subset = df.loc[rndperm[:N],:].copy()\n",
        "    data_subset = df_subset[feat_cols].values\n",
        "\n",
        "    time_start = time.time()\n",
        "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "    tsne_results = tsne.fit_transform(data_subset)\n",
        "    print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "\n",
        "    df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
        "    df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    \n",
        "    plt.title(title)\n",
        "\n",
        "    \n",
        "    sns_plot = sns.scatterplot(\n",
        "        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "        hue=\"y\",\n",
        "        palette=sns.hls_palette(10, l=.5, s=.5),\n",
        "        data=df_subset,\n",
        "        legend=\"full\",\n",
        "        alpha=0.99\n",
        "    )\n",
        "    plt.savefig(f'{plot_path}/{title}.png')\n",
        "    plt.show()\n",
        "    \n",
        "    if dataset is not None:\n",
        "        plt.figure(figsize=(10,10))\n",
        "\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "        sns_plot = sns.scatterplot(\n",
        "            x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "            hue=\"class\",\n",
        "            palette=sns.hls_palette(2, l=.5, s=.5),\n",
        "            data=df_subset,\n",
        "            legend=\"full\",\n",
        "            alpha=0.99\n",
        "        )\n",
        "        plt.savefig(f'{plot_path}/{title}_dataset.png')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-m35TPG-uMM",
        "colab_type": "code",
        "outputId": "93db786b-de84-4ddc-8406-dc107a5cbe8a",
        "colab": {}
      },
      "source": [
        "def main(conf):\n",
        "    os.makedirs(conf['plot_path'], exist_ok=True)\n",
        "    \n",
        "    svhn_loader, svhn_val_loader, mnist_loader, mnist_val_loader = get_loader(conf)\n",
        "\n",
        "    solver = Solver(conf, svhn_loader, svhn_val_loader, mnist_loader, mnist_val_loader)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # create directories if not exist\n",
        "    if not os.path.exists(conf['model_path']):\n",
        "        os.makedirs(conf['model_path'])\n",
        "    if conf['mode'] == 'train':\n",
        "        solver.train()\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Enables reproducibility of results of torch project\n",
        "    :param seed: seed for randomizers\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def start():\n",
        "    # for reproducibility\n",
        "    set_seed(42)\n",
        "    \n",
        "    parser = {}\n",
        "    # model hyper-parameters\n",
        "    parser.update({'image_size': 32})\n",
        "    parser.update({'num_classes': 10})\n",
        "    parser.update({'alpha_s': 0.5})\n",
        "    parser.update({'alpha_t': 0.8})\n",
        "    parser.update({'beta_c': 1})\n",
        "    parser.update({'beta_sep': 1.5})\n",
        "    parser.update({'beta_p': 4})\n",
        "\n",
        "    # training hyper-parameters\n",
        "    parser.update({'train_iters': 1000})\n",
        "    parser.update({'pretrain_iters': 5000})\n",
        "    parser.update({'batch_size': 1024})\n",
        "    parser.update({'num_workers': 2})\n",
        "    parser.update({'lr': 0.001})\n",
        "    parser.update({'lr_d': 0.001})\n",
        "    parser.update({'beta1': 0.5})\n",
        "    parser.update({'beta2': 0.999})\n",
        "\n",
        "    # misc\n",
        "    parser.update({'mode': 'train'})\n",
        "    parser.update({'model_path': './models'})\n",
        "    parser.update({'plot_path': './plots'})\n",
        "    parser.update({'mnist_path': './data/mnist'})\n",
        "    parser.update({'svhn_path': './data/svhn'})\n",
        "    parser.update({'log_file': './out.txt'})\n",
        "    parser.update({'log_step': 20})\n",
        "\n",
        "    # clean up log file\n",
        "    with open(parser['log_file'], 'w') as f:\n",
        "        f.close()\n",
        "    \n",
        "    main(parser)\n",
        "\n",
        "start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/svhn/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/svhn/test_32x32.mat\n",
            "72, 59, 20\n",
            "Pretrain:\n",
            "*********\n",
            "[50/5000] classification loss: 2.0229; source accuracy  0.4268\n",
            "\n",
            "Test Target Accuracy (Overall) [2512 / 10000]: 25%\n",
            "\n",
            "Test Source Accuracy (Overall) [10498 / 26032]: 40%\n",
            "Pretrain time remaining 13.7 min\n",
            "[100/5000] classification loss: 1.8734; source accuracy  0.5820\n",
            "\n",
            "Test Target Accuracy (Overall) [3687 / 10000]: 36%\n",
            "\n",
            "Test Source Accuracy (Overall) [14709 / 26032]: 56%\n",
            "Pretrain time remaining 15.9 min\n",
            "[150/5000] classification loss: 1.8047; source accuracy  0.6738\n",
            "\n",
            "Test Target Accuracy (Overall) [4060 / 10000]: 40%\n",
            "\n",
            "Test Source Accuracy (Overall) [17477 / 26032]: 67%\n",
            "Pretrain time remaining 16.9 min\n",
            "[200/5000] classification loss: 1.6944; source accuracy  0.7598\n",
            "\n",
            "Test Target Accuracy (Overall) [4832 / 10000]: 48%\n",
            "\n",
            "Test Source Accuracy (Overall) [19306 / 26032]: 74%\n",
            "Pretrain time remaining 17.0 min\n",
            "[250/5000] classification loss: 1.6099; source accuracy  0.8594\n",
            "\n",
            "Test Target Accuracy (Overall) [5588 / 10000]: 55%\n",
            "\n",
            "Test Source Accuracy (Overall) [21446 / 26032]: 82%\n",
            "Pretrain time remaining 17.0 min\n",
            "[300/5000] classification loss: 1.5882; source accuracy  0.8809\n",
            "\n",
            "Test Target Accuracy (Overall) [5985 / 10000]: 59%\n",
            "\n",
            "Test Source Accuracy (Overall) [22105 / 26032]: 84%\n",
            "Pretrain time remaining 16.9 min\n",
            "[350/5000] classification loss: 1.5919; source accuracy  0.8828\n",
            "\n",
            "Test Target Accuracy (Overall) [5968 / 10000]: 59%\n",
            "\n",
            "Test Source Accuracy (Overall) [22229 / 26032]: 85%\n",
            "Pretrain time remaining 16.8 min\n",
            "[400/5000] classification loss: 1.5806; source accuracy  0.8896\n",
            "\n",
            "Test Target Accuracy (Overall) [5994 / 10000]: 59%\n",
            "\n",
            "Test Source Accuracy (Overall) [22423 / 26032]: 86%\n",
            "Pretrain time remaining 16.7 min\n",
            "[450/5000] classification loss: 1.5736; source accuracy  0.8896\n",
            "\n",
            "Test Target Accuracy (Overall) [5785 / 10000]: 57%\n",
            "\n",
            "Test Source Accuracy (Overall) [22506 / 26032]: 86%\n",
            "Pretrain time remaining 16.5 min\n",
            "[500/5000] classification loss: 1.5637; source accuracy  0.9023\n",
            "\n",
            "Test Target Accuracy (Overall) [5902 / 10000]: 59%\n",
            "\n",
            "Test Source Accuracy (Overall) [22701 / 26032]: 87%\n",
            "Pretrain time remaining 16.4 min\n",
            "[550/5000] classification loss: 1.5544; source accuracy  0.9131\n",
            "\n",
            "Test Target Accuracy (Overall) [6014 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [22565 / 26032]: 86%\n",
            "Pretrain time remaining 16.2 min\n",
            "[600/5000] classification loss: 1.5540; source accuracy  0.9199\n",
            "\n",
            "Test Target Accuracy (Overall) [6086 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [22739 / 26032]: 87%\n",
            "Pretrain time remaining 16.1 min\n",
            "[650/5000] classification loss: 1.5388; source accuracy  0.9268\n",
            "\n",
            "Test Target Accuracy (Overall) [5732 / 10000]: 57%\n",
            "\n",
            "Test Source Accuracy (Overall) [22755 / 26032]: 87%\n",
            "Pretrain time remaining 15.9 min\n",
            "[700/5000] classification loss: 1.5692; source accuracy  0.9023\n",
            "\n",
            "Test Target Accuracy (Overall) [6070 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [22830 / 26032]: 87%\n",
            "Pretrain time remaining 15.7 min\n",
            "[750/5000] classification loss: 1.5600; source accuracy  0.9160\n",
            "\n",
            "Test Target Accuracy (Overall) [6342 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [22816 / 26032]: 87%\n",
            "Pretrain time remaining 15.6 min\n",
            "[800/5000] classification loss: 1.5285; source accuracy  0.9365\n",
            "\n",
            "Test Target Accuracy (Overall) [6174 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [22931 / 26032]: 88%\n",
            "Pretrain time remaining 15.4 min\n",
            "[850/5000] classification loss: 1.5300; source accuracy  0.9326\n",
            "\n",
            "Test Target Accuracy (Overall) [5787 / 10000]: 57%\n",
            "\n",
            "Test Source Accuracy (Overall) [22851 / 26032]: 87%\n",
            "Pretrain time remaining 15.2 min\n",
            "[900/5000] classification loss: 1.5315; source accuracy  0.9346\n",
            "\n",
            "Test Target Accuracy (Overall) [5697 / 10000]: 56%\n",
            "\n",
            "Test Source Accuracy (Overall) [22897 / 26032]: 87%\n",
            "Pretrain time remaining 15.1 min\n",
            "[950/5000] classification loss: 1.5406; source accuracy  0.9307\n",
            "\n",
            "Test Target Accuracy (Overall) [6166 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [22908 / 26032]: 87%\n",
            "Pretrain time remaining 14.9 min\n",
            "[1000/5000] classification loss: 1.5345; source accuracy  0.9336\n",
            "\n",
            "Test Target Accuracy (Overall) [5738 / 10000]: 57%\n",
            "\n",
            "Test Source Accuracy (Overall) [23083 / 26032]: 88%\n",
            "Pretrain time remaining 14.7 min\n",
            "[1050/5000] classification loss: 1.5500; source accuracy  0.9150\n",
            "\n",
            "Test Target Accuracy (Overall) [6323 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23039 / 26032]: 88%\n",
            "Pretrain time remaining 14.5 min\n",
            "[1100/5000] classification loss: 1.5351; source accuracy  0.9307\n",
            "\n",
            "Test Target Accuracy (Overall) [6058 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [22981 / 26032]: 88%\n",
            "Pretrain time remaining 14.4 min\n",
            "[1150/5000] classification loss: 1.5249; source accuracy  0.9434\n",
            "\n",
            "Test Target Accuracy (Overall) [6002 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [22915 / 26032]: 88%\n",
            "Pretrain time remaining 14.2 min\n",
            "[1200/5000] classification loss: 1.5204; source accuracy  0.9414\n",
            "\n",
            "Test Target Accuracy (Overall) [6189 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23115 / 26032]: 88%\n",
            "Pretrain time remaining 14.0 min\n",
            "[1250/5000] classification loss: 1.5238; source accuracy  0.9443\n",
            "\n",
            "Test Target Accuracy (Overall) [6372 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23140 / 26032]: 88%\n",
            "Pretrain time remaining 13.8 min\n",
            "[1300/5000] classification loss: 1.5217; source accuracy  0.9424\n",
            "\n",
            "Test Target Accuracy (Overall) [6195 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23120 / 26032]: 88%\n",
            "Pretrain time remaining 13.7 min\n",
            "[1350/5000] classification loss: 1.5201; source accuracy  0.9492\n",
            "\n",
            "Test Target Accuracy (Overall) [6193 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23118 / 26032]: 88%\n",
            "Pretrain time remaining 13.5 min\n",
            "[1400/5000] classification loss: 1.5239; source accuracy  0.9443\n",
            "\n",
            "Test Target Accuracy (Overall) [6200 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23135 / 26032]: 88%\n",
            "Pretrain time remaining 13.3 min\n",
            "[1450/5000] classification loss: 1.5068; source accuracy  0.9590\n",
            "\n",
            "Test Target Accuracy (Overall) [5977 / 10000]: 59%\n",
            "\n",
            "Test Source Accuracy (Overall) [23170 / 26032]: 89%\n",
            "Pretrain time remaining 13.1 min\n",
            "[1500/5000] classification loss: 1.5069; source accuracy  0.9580\n",
            "\n",
            "Test Target Accuracy (Overall) [6153 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23206 / 26032]: 89%\n",
            "Pretrain time remaining 12.9 min\n",
            "[1550/5000] classification loss: 1.5069; source accuracy  0.9521\n",
            "\n",
            "Test Target Accuracy (Overall) [6156 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23070 / 26032]: 88%\n",
            "Pretrain time remaining 12.8 min\n",
            "[1600/5000] classification loss: 1.5053; source accuracy  0.9619\n",
            "\n",
            "Test Target Accuracy (Overall) [6086 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [23196 / 26032]: 89%\n",
            "Pretrain time remaining 12.6 min\n",
            "[1650/5000] classification loss: 1.5098; source accuracy  0.9609\n",
            "\n",
            "Test Target Accuracy (Overall) [6165 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23160 / 26032]: 88%\n",
            "Pretrain time remaining 12.4 min\n",
            "[1700/5000] classification loss: 1.5076; source accuracy  0.9521\n",
            "\n",
            "Test Target Accuracy (Overall) [6167 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23288 / 26032]: 89%\n",
            "Pretrain time remaining 12.2 min\n",
            "[1750/5000] classification loss: 1.5037; source accuracy  0.9609\n",
            "\n",
            "Test Target Accuracy (Overall) [6218 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23256 / 26032]: 89%\n",
            "Pretrain time remaining 12.0 min\n",
            "[1800/5000] classification loss: 1.5020; source accuracy  0.9688\n",
            "\n",
            "Test Target Accuracy (Overall) [6446 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23178 / 26032]: 89%\n",
            "Pretrain time remaining 11.8 min\n",
            "[1850/5000] classification loss: 1.4977; source accuracy  0.9629\n",
            "\n",
            "Test Target Accuracy (Overall) [6152 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23253 / 26032]: 89%\n",
            "Pretrain time remaining 11.7 min\n",
            "[1900/5000] classification loss: 1.5169; source accuracy  0.9492\n",
            "\n",
            "Test Target Accuracy (Overall) [6255 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23146 / 26032]: 88%\n",
            "Pretrain time remaining 11.5 min\n",
            "[1950/5000] classification loss: 1.5016; source accuracy  0.9639\n",
            "\n",
            "Test Target Accuracy (Overall) [6260 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23178 / 26032]: 89%\n",
            "Pretrain time remaining 11.3 min\n",
            "[2000/5000] classification loss: 1.5113; source accuracy  0.9580\n",
            "\n",
            "Test Target Accuracy (Overall) [6251 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23309 / 26032]: 89%\n",
            "Pretrain time remaining 11.1 min\n",
            "[2050/5000] classification loss: 1.5021; source accuracy  0.9619\n",
            "\n",
            "Test Target Accuracy (Overall) [6261 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23255 / 26032]: 89%\n",
            "Pretrain time remaining 10.9 min\n",
            "[2100/5000] classification loss: 1.4967; source accuracy  0.9648\n",
            "\n",
            "Test Target Accuracy (Overall) [6041 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [23269 / 26032]: 89%\n",
            "Pretrain time remaining 10.7 min\n",
            "[2150/5000] classification loss: 1.4958; source accuracy  0.9678\n",
            "\n",
            "Test Target Accuracy (Overall) [6524 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23209 / 26032]: 89%\n",
            "Pretrain time remaining 10.6 min\n",
            "[2200/5000] classification loss: 1.5099; source accuracy  0.9551\n",
            "\n",
            "Test Target Accuracy (Overall) [6114 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23354 / 26032]: 89%\n",
            "Pretrain time remaining 10.4 min\n",
            "[2250/5000] classification loss: 1.5006; source accuracy  0.9580\n",
            "\n",
            "Test Target Accuracy (Overall) [6237 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23279 / 26032]: 89%\n",
            "Pretrain time remaining 10.2 min\n",
            "[2300/5000] classification loss: 1.4963; source accuracy  0.9717\n",
            "\n",
            "Test Target Accuracy (Overall) [6297 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23316 / 26032]: 89%\n",
            "Pretrain time remaining 10.0 min\n",
            "[2350/5000] classification loss: 1.5051; source accuracy  0.9590\n",
            "\n",
            "Test Target Accuracy (Overall) [6197 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23258 / 26032]: 89%\n",
            "Pretrain time remaining 9.8 min\n",
            "[2400/5000] classification loss: 1.5029; source accuracy  0.9629\n",
            "\n",
            "Test Target Accuracy (Overall) [6526 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23267 / 26032]: 89%\n",
            "Pretrain time remaining 9.7 min\n",
            "[2450/5000] classification loss: 1.4865; source accuracy  0.9766\n",
            "\n",
            "Test Target Accuracy (Overall) [6429 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23246 / 26032]: 89%\n",
            "Pretrain time remaining 9.5 min\n",
            "[2500/5000] classification loss: 1.4963; source accuracy  0.9678\n",
            "\n",
            "Test Target Accuracy (Overall) [6357 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23358 / 26032]: 89%\n",
            "Pretrain time remaining 9.3 min\n",
            "[2550/5000] classification loss: 1.5055; source accuracy  0.9590\n",
            "\n",
            "Test Target Accuracy (Overall) [6536 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23280 / 26032]: 89%\n",
            "Pretrain time remaining 9.1 min\n",
            "[2600/5000] classification loss: 1.5015; source accuracy  0.9717\n",
            "\n",
            "Test Target Accuracy (Overall) [6572 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23351 / 26032]: 89%\n",
            "Pretrain time remaining 8.9 min\n",
            "[2650/5000] classification loss: 1.4958; source accuracy  0.9639\n",
            "\n",
            "Test Target Accuracy (Overall) [6404 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23375 / 26032]: 89%\n",
            "Pretrain time remaining 8.7 min\n",
            "[2700/5000] classification loss: 1.4970; source accuracy  0.9629\n",
            "\n",
            "Test Target Accuracy (Overall) [6518 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23381 / 26032]: 89%\n",
            "Pretrain time remaining 8.5 min\n",
            "[2750/5000] classification loss: 1.4937; source accuracy  0.9736\n",
            "\n",
            "Test Target Accuracy (Overall) [6320 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23414 / 26032]: 89%\n",
            "Pretrain time remaining 8.4 min\n",
            "[2800/5000] classification loss: 1.4935; source accuracy  0.9688\n",
            "\n",
            "Test Target Accuracy (Overall) [6247 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23395 / 26032]: 89%\n",
            "Pretrain time remaining 8.2 min\n",
            "[2850/5000] classification loss: 1.4907; source accuracy  0.9736\n",
            "\n",
            "Test Target Accuracy (Overall) [6441 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23438 / 26032]: 90%\n",
            "Pretrain time remaining 8.0 min\n",
            "[2900/5000] classification loss: 1.4943; source accuracy  0.9678\n",
            "\n",
            "Test Target Accuracy (Overall) [6353 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23344 / 26032]: 89%\n",
            "Pretrain time remaining 7.8 min\n",
            "[2950/5000] classification loss: 1.4864; source accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [6404 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23337 / 26032]: 89%\n",
            "Pretrain time remaining 7.6 min\n",
            "[3000/5000] classification loss: 1.4922; source accuracy  0.9727\n",
            "\n",
            "Test Target Accuracy (Overall) [6040 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [23320 / 26032]: 89%\n",
            "Pretrain time remaining 7.4 min\n",
            "[3050/5000] classification loss: 1.4816; source accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [6180 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23469 / 26032]: 90%\n",
            "Pretrain time remaining 7.2 min\n",
            "[3100/5000] classification loss: 1.4960; source accuracy  0.9678\n",
            "\n",
            "Test Target Accuracy (Overall) [5886 / 10000]: 58%\n",
            "\n",
            "Test Source Accuracy (Overall) [23358 / 26032]: 89%\n",
            "Pretrain time remaining 7.1 min\n",
            "[3150/5000] classification loss: 1.4788; source accuracy  0.9805\n",
            "\n",
            "Test Target Accuracy (Overall) [6043 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [23314 / 26032]: 89%\n",
            "Pretrain time remaining 6.9 min\n",
            "[3200/5000] classification loss: 1.4951; source accuracy  0.9678\n",
            "\n",
            "Test Target Accuracy (Overall) [6140 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23185 / 26032]: 89%\n",
            "Pretrain time remaining 6.7 min\n",
            "[3250/5000] classification loss: 1.4910; source accuracy  0.9775\n",
            "\n",
            "Test Target Accuracy (Overall) [6194 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23458 / 26032]: 90%\n",
            "Pretrain time remaining 6.5 min\n",
            "[3300/5000] classification loss: 1.4866; source accuracy  0.9746\n",
            "\n",
            "Test Target Accuracy (Overall) [6193 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23347 / 26032]: 89%\n",
            "Pretrain time remaining 6.3 min\n",
            "[3350/5000] classification loss: 1.4812; source accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [6044 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [23391 / 26032]: 89%\n",
            "Pretrain time remaining 6.1 min\n",
            "[3400/5000] classification loss: 1.4853; source accuracy  0.9766\n",
            "\n",
            "Test Target Accuracy (Overall) [6409 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23413 / 26032]: 89%\n",
            "Pretrain time remaining 6.0 min\n",
            "[3450/5000] classification loss: 1.4922; source accuracy  0.9736\n",
            "\n",
            "Test Target Accuracy (Overall) [6456 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23415 / 26032]: 89%\n",
            "Pretrain time remaining 5.8 min\n",
            "[3500/5000] classification loss: 1.4767; source accuracy  0.9863\n",
            "\n",
            "Test Target Accuracy (Overall) [6214 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23286 / 26032]: 89%\n",
            "Pretrain time remaining 5.6 min\n",
            "[3550/5000] classification loss: 1.4905; source accuracy  0.9707\n",
            "\n",
            "Test Target Accuracy (Overall) [6494 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23384 / 26032]: 89%\n",
            "Pretrain time remaining 5.4 min\n",
            "[3600/5000] classification loss: 1.4855; source accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [6049 / 10000]: 60%\n",
            "\n",
            "Test Source Accuracy (Overall) [23432 / 26032]: 90%\n",
            "Pretrain time remaining 5.2 min\n",
            "[3650/5000] classification loss: 1.4849; source accuracy  0.9766\n",
            "\n",
            "Test Target Accuracy (Overall) [6345 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23445 / 26032]: 90%\n",
            "Pretrain time remaining 5.0 min\n",
            "[3700/5000] classification loss: 1.4867; source accuracy  0.9775\n",
            "\n",
            "Test Target Accuracy (Overall) [6212 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23456 / 26032]: 90%\n",
            "Pretrain time remaining 4.8 min\n",
            "[3750/5000] classification loss: 1.4942; source accuracy  0.9736\n",
            "\n",
            "Test Target Accuracy (Overall) [6320 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23420 / 26032]: 89%\n",
            "Pretrain time remaining 4.7 min\n",
            "[3800/5000] classification loss: 1.4850; source accuracy  0.9805\n",
            "\n",
            "Test Target Accuracy (Overall) [6178 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23383 / 26032]: 89%\n",
            "Pretrain time remaining 4.5 min\n",
            "[3850/5000] classification loss: 1.4770; source accuracy  0.9854\n",
            "\n",
            "Test Target Accuracy (Overall) [6263 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23366 / 26032]: 89%\n",
            "Pretrain time remaining 4.3 min\n",
            "[3900/5000] classification loss: 1.4884; source accuracy  0.9746\n",
            "\n",
            "Test Target Accuracy (Overall) [6214 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23479 / 26032]: 90%\n",
            "Pretrain time remaining 4.1 min\n",
            "[3950/5000] classification loss: 1.4854; source accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [6208 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23490 / 26032]: 90%\n",
            "Pretrain time remaining 3.9 min\n",
            "[4000/5000] classification loss: 1.4880; source accuracy  0.9736\n",
            "\n",
            "Test Target Accuracy (Overall) [6101 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23516 / 26032]: 90%\n",
            "Pretrain time remaining 3.7 min\n",
            "[4050/5000] classification loss: 1.4886; source accuracy  0.9707\n",
            "\n",
            "Test Target Accuracy (Overall) [6243 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23392 / 26032]: 89%\n",
            "Pretrain time remaining 3.5 min\n",
            "[4100/5000] classification loss: 1.4816; source accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [6268 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23407 / 26032]: 89%\n",
            "Pretrain time remaining 3.4 min\n",
            "[4150/5000] classification loss: 1.4831; source accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [6230 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23297 / 26032]: 89%\n",
            "Pretrain time remaining 3.2 min\n",
            "[4200/5000] classification loss: 1.4835; source accuracy  0.9746\n",
            "\n",
            "Test Target Accuracy (Overall) [6156 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23367 / 26032]: 89%\n",
            "Pretrain time remaining 3.0 min\n",
            "[4250/5000] classification loss: 1.4844; source accuracy  0.9775\n",
            "\n",
            "Test Target Accuracy (Overall) [6244 / 10000]: 62%\n",
            "\n",
            "Test Source Accuracy (Overall) [23394 / 26032]: 89%\n",
            "Pretrain time remaining 2.8 min\n",
            "[4300/5000] classification loss: 1.4802; source accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [6405 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23541 / 26032]: 90%\n",
            "Pretrain time remaining 2.6 min\n",
            "[4350/5000] classification loss: 1.4914; source accuracy  0.9717\n",
            "\n",
            "Test Target Accuracy (Overall) [6395 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23477 / 26032]: 90%\n",
            "Pretrain time remaining 2.4 min\n",
            "[4400/5000] classification loss: 1.4848; source accuracy  0.9766\n",
            "\n",
            "Test Target Accuracy (Overall) [6500 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23455 / 26032]: 90%\n",
            "Pretrain time remaining 2.2 min\n",
            "[4450/5000] classification loss: 1.4798; source accuracy  0.9844\n",
            "\n",
            "Test Target Accuracy (Overall) [6396 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23415 / 26032]: 89%\n",
            "Pretrain time remaining 2.0 min\n",
            "[4500/5000] classification loss: 1.4802; source accuracy  0.9805\n",
            "\n",
            "Test Target Accuracy (Overall) [6521 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23471 / 26032]: 90%\n",
            "Pretrain time remaining 1.9 min\n",
            "[4550/5000] classification loss: 1.4777; source accuracy  0.9844\n",
            "\n",
            "Test Target Accuracy (Overall) [6347 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23530 / 26032]: 90%\n",
            "Pretrain time remaining 1.7 min\n",
            "[4600/5000] classification loss: 1.4814; source accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [6460 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23491 / 26032]: 90%\n",
            "Pretrain time remaining 1.5 min\n",
            "[4650/5000] classification loss: 1.4859; source accuracy  0.9766\n",
            "\n",
            "Test Target Accuracy (Overall) [6690 / 10000]: 66%\n",
            "\n",
            "Test Source Accuracy (Overall) [23493 / 26032]: 90%\n",
            "Pretrain time remaining 1.3 min\n",
            "[4700/5000] classification loss: 1.4821; source accuracy  0.9814\n",
            "\n",
            "Test Target Accuracy (Overall) [6557 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23508 / 26032]: 90%\n",
            "Pretrain time remaining 1.1 min\n",
            "[4750/5000] classification loss: 1.4750; source accuracy  0.9844\n",
            "\n",
            "Test Target Accuracy (Overall) [6329 / 10000]: 63%\n",
            "\n",
            "Test Source Accuracy (Overall) [23477 / 26032]: 90%\n",
            "Pretrain time remaining 0.9 min\n",
            "[4800/5000] classification loss: 1.4784; source accuracy  0.9805\n",
            "\n",
            "Test Target Accuracy (Overall) [6572 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23483 / 26032]: 90%\n",
            "Pretrain time remaining 0.7 min\n",
            "[4850/5000] classification loss: 1.4841; source accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [6400 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23456 / 26032]: 90%\n",
            "Pretrain time remaining 0.6 min\n",
            "[4900/5000] classification loss: 1.4755; source accuracy  0.9863\n",
            "\n",
            "Test Target Accuracy (Overall) [6509 / 10000]: 65%\n",
            "\n",
            "Test Source Accuracy (Overall) [23388 / 26032]: 89%\n",
            "Pretrain time remaining 0.4 min\n",
            "[4950/5000] classification loss: 1.4814; source accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [6409 / 10000]: 64%\n",
            "\n",
            "Test Source Accuracy (Overall) [23424 / 26032]: 89%\n",
            "Pretrain time remaining 0.2 min\n",
            "[5000/5000] classification loss: 1.4867; source accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [6106 / 10000]: 61%\n",
            "\n",
            "Test Source Accuracy (Overall) [23370 / 26032]: 89%\n",
            "Pretrain time remaining 0.0 min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/mmavlyutov/alex/venv/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/home/mmavlyutov/alex/venv/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/home/mmavlyutov/alex/venv/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/home/mmavlyutov/alex/venv/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/home/mmavlyutov/alex/venv/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/home/mmavlyutov/alex/venv/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Second:\n",
            "******\n",
            "Iteration [20 / 1000]\n",
            "Max accuracy: 0.00 on iteration 0; Current source  accuracy  0.9512\n",
            "\n",
            "Test Target Accuracy (Overall) [8897 / 10000]: 88%\n",
            "\n",
            "Test Source Accuracy (Overall) [21232 / 26032]: 81%\n",
            "Train time remaining 32.4 min\n",
            "Iteration [40 / 1000]\n",
            "Max accuracy: 88.97 on iteration 19; Current source  accuracy  0.9551\n",
            "\n",
            "Test Target Accuracy (Overall) [8897 / 10000]: 88%\n",
            "\n",
            "Test Source Accuracy (Overall) [22266 / 26032]: 85%\n",
            "Train time remaining 34.0 min\n",
            "Iteration [60 / 1000]\n",
            "Max accuracy: 88.97 on iteration 19; Current source  accuracy  0.9619\n",
            "\n",
            "Test Target Accuracy (Overall) [9276 / 10000]: 92%\n",
            "\n",
            "Test Source Accuracy (Overall) [22394 / 26032]: 86%\n",
            "Train time remaining 34.2 min\n",
            "Iteration [80 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9648\n",
            "\n",
            "Test Target Accuracy (Overall) [9065 / 10000]: 90%\n",
            "\n",
            "Test Source Accuracy (Overall) [22561 / 26032]: 86%\n",
            "Train time remaining 33.9 min\n",
            "Iteration [100 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9746\n",
            "\n",
            "Test Target Accuracy (Overall) [8753 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22611 / 26032]: 86%\n",
            "Train time remaining 33.3 min\n",
            "Iteration [120 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9736\n",
            "\n",
            "Test Target Accuracy (Overall) [8977 / 10000]: 89%\n",
            "\n",
            "Test Source Accuracy (Overall) [22493 / 26032]: 86%\n",
            "Train time remaining 32.8 min\n",
            "Iteration [140 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9727\n",
            "\n",
            "Test Target Accuracy (Overall) [8861 / 10000]: 88%\n",
            "\n",
            "Test Source Accuracy (Overall) [22588 / 26032]: 86%\n",
            "Train time remaining 32.1 min\n",
            "Iteration [160 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9756\n",
            "\n",
            "Test Target Accuracy (Overall) [8996 / 10000]: 89%\n",
            "\n",
            "Test Source Accuracy (Overall) [23018 / 26032]: 88%\n",
            "Train time remaining 31.4 min\n",
            "Iteration [180 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9756\n",
            "\n",
            "Test Target Accuracy (Overall) [9039 / 10000]: 90%\n",
            "\n",
            "Test Source Accuracy (Overall) [22912 / 26032]: 88%\n",
            "Train time remaining 30.7 min\n",
            "Iteration [200 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9785\n",
            "\n",
            "Test Target Accuracy (Overall) [8817 / 10000]: 88%\n",
            "\n",
            "Test Source Accuracy (Overall) [22892 / 26032]: 87%\n",
            "Train time remaining 30.0 min\n",
            "Iteration [220 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9785\n",
            "\n",
            "Test Target Accuracy (Overall) [8900 / 10000]: 89%\n",
            "\n",
            "Test Source Accuracy (Overall) [23133 / 26032]: 88%\n",
            "Train time remaining 29.2 min\n",
            "Iteration [240 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [8792 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22847 / 26032]: 87%\n",
            "Train time remaining 28.5 min\n",
            "Iteration [260 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [8881 / 10000]: 88%\n",
            "\n",
            "Test Source Accuracy (Overall) [22954 / 26032]: 88%\n",
            "Train time remaining 27.8 min\n",
            "Iteration [280 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9775\n",
            "\n",
            "Test Target Accuracy (Overall) [8792 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22883 / 26032]: 87%\n",
            "Train time remaining 27.0 min\n",
            "Iteration [300 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [8779 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [23125 / 26032]: 88%\n",
            "Train time remaining 26.3 min\n",
            "Iteration [320 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9863\n",
            "\n",
            "Test Target Accuracy (Overall) [8761 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22480 / 26032]: 86%\n",
            "Train time remaining 25.5 min\n",
            "Iteration [340 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9785\n",
            "\n",
            "Test Target Accuracy (Overall) [8796 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22839 / 26032]: 87%\n",
            "Train time remaining 24.8 min\n",
            "Iteration [360 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9834\n",
            "\n",
            "Test Target Accuracy (Overall) [8805 / 10000]: 88%\n",
            "\n",
            "Test Source Accuracy (Overall) [22809 / 26032]: 87%\n",
            "Train time remaining 24.0 min\n",
            "Iteration [380 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9834\n",
            "\n",
            "Test Target Accuracy (Overall) [8759 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [23079 / 26032]: 88%\n",
            "Train time remaining 23.3 min\n",
            "Iteration [400 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [8716 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22986 / 26032]: 88%\n",
            "Train time remaining 22.6 min\n",
            "Iteration [420 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [8694 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [22687 / 26032]: 87%\n",
            "Train time remaining 21.8 min\n",
            "Iteration [440 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9893\n",
            "\n",
            "Test Target Accuracy (Overall) [8711 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22979 / 26032]: 88%\n",
            "Train time remaining 21.1 min\n",
            "Iteration [460 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9883\n",
            "\n",
            "Test Target Accuracy (Overall) [8704 / 10000]: 87%\n",
            "\n",
            "Test Source Accuracy (Overall) [22957 / 26032]: 88%\n",
            "Train time remaining 20.3 min\n",
            "Iteration [480 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9893\n",
            "\n",
            "Test Target Accuracy (Overall) [8694 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [22810 / 26032]: 87%\n",
            "Train time remaining 19.6 min\n",
            "Iteration [500 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9814\n",
            "\n",
            "Test Target Accuracy (Overall) [8664 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [23094 / 26032]: 88%\n",
            "Train time remaining 18.8 min\n",
            "Iteration [520 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9775\n",
            "\n",
            "Test Target Accuracy (Overall) [8675 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [23112 / 26032]: 88%\n",
            "Train time remaining 18.1 min\n",
            "Iteration [540 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9883\n",
            "\n",
            "Test Target Accuracy (Overall) [8658 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [23103 / 26032]: 88%\n",
            "Train time remaining 17.3 min\n",
            "Iteration [560 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9844\n",
            "\n",
            "Test Target Accuracy (Overall) [8665 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [22970 / 26032]: 88%\n",
            "Train time remaining 16.6 min\n",
            "Iteration [580 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9854\n",
            "\n",
            "Test Target Accuracy (Overall) [8630 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [22960 / 26032]: 88%\n",
            "Train time remaining 15.8 min\n",
            "Iteration [600 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9873\n",
            "\n",
            "Test Target Accuracy (Overall) [8650 / 10000]: 86%\n",
            "\n",
            "Test Source Accuracy (Overall) [23022 / 26032]: 88%\n",
            "Train time remaining 15.1 min\n",
            "Iteration [620 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9932\n",
            "\n",
            "Test Target Accuracy (Overall) [8582 / 10000]: 85%\n",
            "\n",
            "Test Source Accuracy (Overall) [22989 / 26032]: 88%\n",
            "Train time remaining 14.3 min\n",
            "Iteration [640 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9824\n",
            "\n",
            "Test Target Accuracy (Overall) [8587 / 10000]: 85%\n",
            "\n",
            "Test Source Accuracy (Overall) [22997 / 26032]: 88%\n",
            "Train time remaining 13.6 min\n",
            "Iteration [660 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9844\n",
            "\n",
            "Test Target Accuracy (Overall) [8544 / 10000]: 85%\n",
            "\n",
            "Test Source Accuracy (Overall) [23046 / 26032]: 88%\n",
            "Train time remaining 12.8 min\n",
            "Iteration [680 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9844\n",
            "\n",
            "Test Target Accuracy (Overall) [8561 / 10000]: 85%\n",
            "\n",
            "Test Source Accuracy (Overall) [22945 / 26032]: 88%\n",
            "Train time remaining 12.1 min\n",
            "Iteration [700 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9814\n",
            "\n",
            "Test Target Accuracy (Overall) [8580 / 10000]: 85%\n",
            "\n",
            "Test Source Accuracy (Overall) [22835 / 26032]: 87%\n",
            "Train time remaining 11.3 min\n",
            "Iteration [720 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9893\n",
            "\n",
            "Test Target Accuracy (Overall) [8556 / 10000]: 85%\n",
            "\n",
            "Test Source Accuracy (Overall) [22967 / 26032]: 88%\n",
            "Train time remaining 10.6 min\n",
            "Iteration [740 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9854\n",
            "\n",
            "Test Target Accuracy (Overall) [8527 / 10000]: 85%\n",
            "\n",
            "Test Source Accuracy (Overall) [22925 / 26032]: 88%\n",
            "Train time remaining 9.8 min\n",
            "Iteration [760 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9863\n",
            "\n",
            "Test Target Accuracy (Overall) [8465 / 10000]: 84%\n",
            "\n",
            "Test Source Accuracy (Overall) [22828 / 26032]: 87%\n",
            "Train time remaining 9.0 min\n",
            "Iteration [780 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9756\n",
            "\n",
            "Test Target Accuracy (Overall) [8445 / 10000]: 84%\n",
            "\n",
            "Test Source Accuracy (Overall) [22894 / 26032]: 87%\n",
            "Train time remaining 8.3 min\n",
            "Iteration [800 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9883\n",
            "\n",
            "Test Target Accuracy (Overall) [8466 / 10000]: 84%\n",
            "\n",
            "Test Source Accuracy (Overall) [22894 / 26032]: 87%\n",
            "Train time remaining 7.5 min\n",
            "Iteration [820 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9883\n",
            "\n",
            "Test Target Accuracy (Overall) [8415 / 10000]: 84%\n",
            "\n",
            "Test Source Accuracy (Overall) [22746 / 26032]: 87%\n",
            "Train time remaining 6.8 min\n",
            "Iteration [840 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9805\n",
            "\n",
            "Test Target Accuracy (Overall) [8372 / 10000]: 83%\n",
            "\n",
            "Test Source Accuracy (Overall) [22809 / 26032]: 87%\n",
            "Train time remaining 6.0 min\n",
            "Iteration [860 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9775\n",
            "\n",
            "Test Target Accuracy (Overall) [8375 / 10000]: 83%\n",
            "\n",
            "Test Source Accuracy (Overall) [22841 / 26032]: 87%\n",
            "Train time remaining 5.3 min\n",
            "Iteration [880 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9785\n",
            "\n",
            "Test Target Accuracy (Overall) [8374 / 10000]: 83%\n",
            "\n",
            "Test Source Accuracy (Overall) [22877 / 26032]: 87%\n",
            "Train time remaining 4.5 min\n",
            "Iteration [900 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9873\n",
            "\n",
            "Test Target Accuracy (Overall) [8391 / 10000]: 83%\n",
            "\n",
            "Test Source Accuracy (Overall) [22841 / 26032]: 87%\n",
            "Train time remaining 3.8 min\n",
            "Iteration [920 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9795\n",
            "\n",
            "Test Target Accuracy (Overall) [8324 / 10000]: 83%\n",
            "\n",
            "Test Source Accuracy (Overall) [22903 / 26032]: 87%\n",
            "Train time remaining 3.0 min\n",
            "Iteration [940 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9912\n",
            "\n",
            "Test Target Accuracy (Overall) [8389 / 10000]: 83%\n",
            "\n",
            "Test Source Accuracy (Overall) [22889 / 26032]: 87%\n",
            "Train time remaining 2.3 min\n",
            "Iteration [960 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9863\n",
            "\n",
            "Test Target Accuracy (Overall) [8375 / 10000]: 83%\n",
            "\n",
            "Test Source Accuracy (Overall) [22855 / 26032]: 87%\n",
            "Train time remaining 1.5 min\n",
            "Iteration [980 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9863\n",
            "\n",
            "Test Target Accuracy (Overall) [8291 / 10000]: 82%\n",
            "\n",
            "Test Source Accuracy (Overall) [22815 / 26032]: 87%\n",
            "Train time remaining 0.8 min\n",
            "Iteration [1000 / 1000]\n",
            "Max accuracy: 92.76 on iteration 59; Current source  accuracy  0.9883\n",
            "\n",
            "Test Target Accuracy (Overall) [8258 / 10000]: 82%\n",
            "\n",
            "Test Source Accuracy (Overall) [22773 / 26032]: 87%\n",
            "Train time remaining 0.0 min\n",
            "Test Accuracy of     0: 99% (973/980)\n",
            "Test Accuracy of     1: 99% (1126/1135)\n",
            "Test Accuracy of     2: 98% (1012/1032)\n",
            "Test Accuracy of     3: 95% (967/1010)\n",
            "Test Accuracy of     4: 99% (974/982)\n",
            "Test Accuracy of     5: 97% (868/892)\n",
            "Test Accuracy of     6:  3% (37/958)\n",
            "Test Accuracy of     7: 94% (974/1028)\n",
            "Test Accuracy of     8: 73% (719/974)\n",
            "Test Accuracy of     9: 60% (608/1009)\n",
            "\n",
            "Test Target Accuracy (Overall) [8258 / 10000]: 82%\n",
            "\n",
            "Test Source Accuracy (Overall) [22773 / 26032]: 87%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/mmavlyutov/alex/venv/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net_D. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkxqZrAB-uMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}